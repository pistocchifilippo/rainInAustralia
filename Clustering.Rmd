---
title: "Preprocessing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(dplyr)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(stats)
library(factoextra)
library(FactoMineR)
library(mclust)
library(cluster)
```


In the following chunk of code a tiny data pre processing will be applied to the dataset in order to prepare it to execute few clustering algorithms on top of it. To apply the clustering algorithms below the input dataset must be composed by **numeric variables**, therefore not numeric data will be discarded.
The analysis will be performed considering jsut climatic descriptors.
```{r}
# Need caret library

# To have reproducibility of the sampling
set.seed(123)

scaled <- read.csv('scaled.csv')

# Removing the first column describing the number of the row
scaled <- scaled[2:ncol(scaled)]

# Keeping just numeric values
df <- scaled %>% dplyr::select(where(is.numeric))

# Random sampling
df <- df[sample(nrow(df),1000), ]
```

The first approach with clustering method have been with the traditional partition methodology applying K-Means algorithm, since is the computationally less expensive technique. The algorithm have been executed, looking for 2, 3, 4 and 5 clusters (`centers = x`) in order to look for some likely shapes of the clusters.
It is plain that datas have the hape of a cloud, therefore it is not going to be possible distinguish clean clusters.
```{r}
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)

p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

To determine the optimal number of clusters we adopted the **silhouette** method, with the respective code `method = "silhouette"`. The output suggest an optimal number of clusters equal to two.
```{r}
fviz_nbclust(df, kmeans, method = "silhouette")
```

The object of our analysis then will be based on this plot.
```{r}
fviz_cluster(k2, geom = "point", data = df)
```

As the silhouette method suggested will be studied the clustering with k equals to 2. For the interpretation of the obtained results, showing the centers `k2$centers` will help to associate each cluster to particular feature.
It is clear that the first cluster (1) is more representative for the high **temperature** sampling while the second cluster (2) is more representative for the low temperatures. High temperature cluster and low temperature cluster differ also in term of **humidity** and **pressure**, presenting respectively low and high values.
```{r}
k2$centers
```

Another trial to identify other kind of clusters shapes have been done applying a mixed approach, using a hierarchical clustering to determine the number of clusters. The number of clusters then have been used to set up the `k` parameter in K-Means algorithm (`hkmeans`).
```{r}
res.hk <-hkmeans(df, 4)
fviz_cluster(res.hk, palette = "jco", repel = TRUE, ggtheme = theme_classic())
```
Adopting a higher number of cluster is easier to notice a higher variation in term of clusters specialization.
The most important cluster in this analysis is clearly the number 3 since it is represented by a high value of the `Rainfall` attribute and therefore it is representing the rainy days, that are very important for our analysis, since the goal of the following prediction phase will be focused on classify correctly the variable `Raintomorrow`. According with this cluster, rainy days are characterized by high wind values and low pressure and temperatures.
```{r}
res.hk$centers
```

Since the biggest part of the dataset shows a gaussian distribution, a Gaussian finite mixture model fitted by EM algorithm should achieve good results in terms of clustering.
```{r}
mc<- Mclust(df)
fviz_mclust(mc, "uncertainty", palette = "jco")
```
Gaussian mixture produced as output five clusters of shape **VEV**.
```{r}
mc$G
mc$modelName
```

Now let's start interpreting the output of the clustering. Even this time there is one cluster over representative for the variable rainfall, presenting even higher value than before. As before the features presented by rainy days are almost the same, with the difference that this time the humidity is way higher but than before but the pressure is not that low.
```{r}
mc$parameters$mean
```

Maybe integrate or not...
```{r}
d <- dist(df, method = "euclidean")

fviz_nbclust(df, FUN = hcut, method = "silhouette")

hc.single <- hclust(d, method="single")
clust2 <- cutree(hc.single, k = 2)

fviz_cluster(list(data = d, cluster = clust2))
```